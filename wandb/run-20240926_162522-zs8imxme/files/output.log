  0%|                                                                                                                                                   | 0/8 [00:00<?, ?it/s]/home/user/anaconda3/envs/ch_llm/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/user/anaconda3/envs/ch_llm/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]







100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [06:12<00:00, 46.61s/it]
{'train_runtime': 375.885, 'train_samples_per_second': 2.772, 'train_steps_per_second': 0.021, 'train_loss': 1820.9197998046875, 'epoch': 0.98}
 If there's a warning about missing keys above, please disregard :)